getwd()
source('~/R/Lab1/Lab1Assignment2.R')
source('~/R/Lab1/Lab1Assignment2.R')
source('~/R/Lab1/Lab1Assignment2.R')
source('~/R/Lab1/Lab1Assignment2.R')
bestThetaLogLikelihood
source('~/R/Lab1/Lab1Assignment2.R')
bestThetaBayesian
source('~/R/Lab1/Lab1Assignment2.R')
#Loading the data from tecator.csv.
data <- read.csv2(file="tecator.csv", header=TRUE)
#Checking if a linear model makes sense.
plot(data$Moisture ~ data$Protein) #Yes
#Dividing data into training and test sets.
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
train=data[id,]
#Checking if a linear model makes sense.
plot(data$Moisture ~ data$Protein) #Yes
#Dividing data into training and test sets.
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
train=data[id,]
test=data[-id,]
#Creating m1-m6 with different degrees. Maybe do a loop?
m1 <- lm(Moisture ~ poly(Protein, degree = 1, raw = TRUE), data = train)
m2 <- lm(Moisture ~ poly(Protein, degree = 2, raw = TRUE), data = train)
m3 <- lm(Moisture ~ poly(Protein, degree = 3, raw = TRUE), data = train)
m4 <- lm(Moisture ~ poly(Protein, degree = 4, raw = TRUE), data = train)
m5 <- lm(Moisture ~ poly(Protein, degree = 5, raw = TRUE), data = train)
m6 <- lm(Moisture ~ poly(Protein, degree = 6, raw = TRUE), data = train)
#Calculating MSE for the training data.
mseTrain1 <- mean(m1$residuals^2)
mseTrain2 <- mean(m2$residuals^2)
mseTrain3 <- mean(m3$residuals^2)
mseTrain4 <- mean(m4$residuals^2)
mseTrain5 <- mean(m5$residuals^2)
mseTrain6 <- mean(m6$residuals^2)
mseTrain <- c(mseTrain1, mseTrain2, mseTrain3, mseTrain4, mseTrain5, mseTrain6)
#Predicting with the test data and calculating the MSE.
p1 <- predict(m1, newdata = test, type = "response")
mseTest1 <- mean((p1 - test$Moisture)^2)
p2 <- predict(m2, newdata = test, type = "response")
mseTest2 <- mean((p2 - test$Moisture)^2)
p3 <- predict(m3, newdata = test, type = "response")
mseTest3 <- mean((p3 - test$Moisture)^2)
p4 <- predict(m4, newdata = test, type = "response")
mseTest4 <- mean((p4 - test$Moisture)^2)
p5 <- predict(m5, newdata = test, type = "response")
mseTest5 <- mean((p5 - test$Moisture)^2)
p6 <- predict(m6, newdata = test, type = "response")
mseTest6 <- mean((p6 - test$Moisture)^2)
mseTest <- c(mseTest1, mseTest2, mseTest3, mseTest4, mseTest5, mseTest6)
#Plot booth MSE-arrays.
plot(mseTrain, type="b", col="blue", pch="o", lty=1, xlim=c(0, 7), ylim=c(30, 35))
points(mseTest, type ="b", col="red", pch="*")
points(mseTest, type ="b", col="red", pch="*")
#-------------------------------------------------------------------
library("MASS")
channelFat <- data[, 2:102]
model <- lm(Fat ~ ., data = channelFat)
#stepAIC with how many coefficients are chosen.
step <- stepAIC(model, direction="both")
step$anova
summary(step)
step$rank
#-------------------------------------------------------------------
library("glmnet")
#Ridge
covariates=scale(data[, 2:101])
response=scale(data[, 102])
ridge <- glmnet(as.matrix(covariates), response, alpha=0, family="gaussian")
plot(ridge, xvar="lambda", label=TRUE, xlim=c(-3, 7), ylim=c(-0.18, 0.35))
#-------------------------------------------------------------------
#Lasso
lasso <- glmnet(as.matrix(covariates), response, alpha=1, family="gaussian")
plot(lasso, xvar="lambda", label=TRUE, xlim=c(-7, 0), ylim=c(-3, 5))
plot(ridge, xvar="lambda", label=TRUE, xlim=c(-3, 7), ylim=c(-0.18, 0.35))
#-------------------------------------------------------------------
#Cross-validation
cvLasso <- cv.glmnet(as.matrix(covariates), response, alpha=1, family="gaussian")
cvLasso$lambda.min
plot(cvLasso)
coef(cvLasso, s="lambda.min")
setwd("~/R/Lab1")
install.packages("devtools")
library("devtools")
install_version("rmarkdown", version=1.8)
source('~/R/Lab1/Lab1Assignment1.R')
confusionMatrixTrain0.5
confusionMatrixTest0.5
missratetrain0.5
missratetest0.5
missratetest0.9
missratetrain0.9
missratetrain0.9
missclass(train$Spam, trainProbability0.9)
confusionMatrixTrain0.9
confusionMatrixTest0.9
missclassTrain30
missclassTest30
missclassTrain1
missclassTest1
#Lab 1
#Assignment 1
#Loading the data from spambase.csv.
data <- read.csv2(file="spambase.csv", header=TRUE)
data$Spam <- factor(data$Spam)
#Compute misclassification rate.
missclass = function(X, X1) {
n=length(X)
return(1-sum(diag(table(X,X1)))/n)
}
#Dividing data into training and test sets.
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
train=data[id,]
test=data[-id,]
#Model for logistic regression.
logisticModel <- glm(Spam ~ ., data=train, family="binomial")
#Computing the probability.
trainProbability <- predict(logisticModel, newdata = train, type = "response")
testProbability <- predict(logisticModel, newdata = test, type = "response")
#Changing values in array depending on probability.
trainProbability0.5 <- ifelse(trainProbability > 0.5, 1, 0)
testProbability0.5 <- ifelse(testProbability > 0.5, 1, 0)
#Confusion matrix
confusionMatrixTrain0.5 <- table(Actual_value = train$Spam, Predicted_value = trainProbability0.5)
confusionMatrixTest0.5 <- table(Actual_value = test$Spam, Predicted_value = testProbability0.5)
#Computing misclassification rates.
missratetrain0.5 <- missclass(train$Spam, trainProbability0.5)
missratetest0.5 <- missclass(test$Spam, testProbability0.5)
#missratetest > missratetrain -> overfitted?
#------------------------------------------------------------------------------
#Changing values in array depending on probability.
trainProbability0.9 <- ifelse(trainProbability > 0.9, 1, 0)
testProbability0.9 <- ifelse(testProbability > 0.9, 1, 0)
#Confusion matrix
confusionMatrixTrain0.9 <- table(Actual_value = train$Spam, Predicted_value = trainProbability0.9)
confusionMatrixTest0.9 <- table(Actual_value = test$Spam, Predicted_value = testProbability0.9) #low number of true positives
#Computing misclassification rates.
missratetrain0.9 <- missclass(train$Spam, trainProbability0.9)
missratetest0.9 <- missclass(test$Spam, testProbability0.9)
#What effects did the new rule have? The misclassification rate increased -> worse!
#-----------------------------------------------------------------------------
library("kknn")
#Model for kknn.
kknnSpamTrain30 <- kknn(Spam ~ ., train = train, test = train, k = 30)
kknnSpamTest30 <- kknn(Spam ~ ., train = train, test = test, k = 30)
kknnSpamTrain1 <- kknn(Spam ~ ., train = train, test = train, k = 1)
kknnSpamTest1 <- kknn(Spam ~ ., train = train, test = test, k = 1)
#Computing misclassification rates.
missclassTrain30 <- missclass(train$Spam, kknnSpamTrain30$fitted.values)
missclassTest30 <- missclass(test$Spam, kknnSpamTest30$fitted.values)
missclassTrain1 <- missclass(train$Spam, kknnSpamTrain1$fitted.values)
missclassTest1 <- missclass(test$Spam, kknnSpamTest1$fitted.values)
#Lab 1
#Assignment 2
#Loading the data from machines.csv.
data <- read.csv2(file="machines.csv", header=TRUE)
#Function for calculating the loglikelihood.
calculateProbability = function(x, theta) {
n = dim(x)[1]
probability = n*log(theta) - theta*sum(x)
return(probability)
}
#Select x number of values between minData and maxData.
theta = seq(min(data), max(data), length.out = 1000)
#loglikelihood.
logLikelihood = calculateProbability(data, theta)
bestThetaLogLikelihood = theta[which.max(logLikelihood)]
#6 first observations.
firstSix = as.data.frame(data[1:6, ])
logLikelihoodSix = calculateProbability(firstSix, theta)
plot(theta, logLikelihood, type="l", ylim = c(-150, 0), xlab="Theta", ylab="Log Likelihood", main="Log Likelihood and theta", col="red")
#lines(theta, logLikelihoodSix, col="blue")
#-------------------------------------------------------------------
#Prior + theta
bayesian <- logLikelihood + log(10) - 10*theta
lines(theta, bayesian, col="green")
bestThetaBayesian <- theta[which.max(bayesian)]
#-------------------------------------------------------------------
newObservations <- rexp(50, rate = bestThetaLogLikelihood)
#Histograms.
hist(data$Length, xlim=c(0,5), col="red")
hist(newObservations, add=T, col=rgb(0, 1, 0, 0.5))
plot(theta, logLikelihood, type="l", ylim = c(-150, 0), xlab="Theta", ylab="Log Likelihood", main="Log Likelihood and theta", col="red")
lines(theta, logLikelihoodSix, col="blue")
lines(theta, bayesian, col="green")
bestThetaBayesian <- theta[which.max(bayesian)]
#-------------------------------------------------------------------
newObservations <- rexp(50, rate = bestThetaLogLikelihood)
#Histograms.
hist(data$Length, xlim=c(0,5), col="red")
hist(newObservations, add=T, col=rgb(0, 1, 0, 0.5))
#-------------------------------------------------------------------
newObservations <- rexp(50, rate = bestThetaLogLikelihood)
#Histograms.
hist(data$Length, xlim=c(0,5), col="red")
hist(newObservations, add=T, col=rgb(0, 1, 0, 0.5))
#-------------------------------------------------------------------
set.seed(12345)
newObservations <- rexp(50, rate = bestThetaLogLikelihood)
#Histograms.
hist(data$Length, xlim=c(0,5), col="red")
hist(newObservations, add=T, col=rgb(0, 1, 0, 0.5))
#Histograms.
par(mfrow=c(1,2))
hist(data$Length, xlim=c(0,5), col="red")
hist(newObservations, add=T, col=rgb(0, 1, 0, 0.5))
par(mfrow=c(1,1))
#Histograms.
par(mfrow=c(1,2))
hist(data$Length, xlim=c(0,5), col="red")
hist(newObservations, col=rgb(0, 1, 0, 0.5))
par(mfrow=c(1,1))
#Histograms.
par(mfrow=c(1,2))
hist(data$Length, xlim=c(0,5), col="red", breaks=15)
hist(newObservations, col=rgb(0, 1, 0, 0.5), breaks = 15)
par(mfrow=c(1,1))
#Lab 1
#Assignment 4
#Loading the data from tecator.csv.
data <- read.csv2(file="tecator.csv", header=TRUE)
#Checking if a linear model makes sense.
plot(data$Moisture ~ data$Protein) #Yes
#Dividing data into training and test sets.
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
train=data[id,]
test=data[-id,]
#Creating m1-m6 with different degrees. Maybe do a loop?
m1 <- lm(Moisture ~ poly(Protein, degree = 1, raw = TRUE), data = train)
m2 <- lm(Moisture ~ poly(Protein, degree = 2, raw = TRUE), data = train)
m3 <- lm(Moisture ~ poly(Protein, degree = 3, raw = TRUE), data = train)
m4 <- lm(Moisture ~ poly(Protein, degree = 4, raw = TRUE), data = train)
m5 <- lm(Moisture ~ poly(Protein, degree = 5, raw = TRUE), data = train)
m6 <- lm(Moisture ~ poly(Protein, degree = 6, raw = TRUE), data = train)
#Calculating MSE for the training data.
mseTrain1 <- mean(m1$residuals^2)
mseTrain2 <- mean(m2$residuals^2)
mseTrain3 <- mean(m3$residuals^2)
mseTrain4 <- mean(m4$residuals^2)
mseTrain5 <- mean(m5$residuals^2)
mseTrain6 <- mean(m6$residuals^2)
mseTrain <- c(mseTrain1, mseTrain2, mseTrain3, mseTrain4, mseTrain5, mseTrain6)
#Predicting with the test data and calculating the MSE.
p1 <- predict(m1, newdata = test, type = "response")
mseTest1 <- mean((p1 - test$Moisture)^2)
p2 <- predict(m2, newdata = test, type = "response")
mseTest2 <- mean((p2 - test$Moisture)^2)
p3 <- predict(m3, newdata = test, type = "response")
mseTest3 <- mean((p3 - test$Moisture)^2)
p4 <- predict(m4, newdata = test, type = "response")
mseTest4 <- mean((p4 - test$Moisture)^2)
p5 <- predict(m5, newdata = test, type = "response")
mseTest5 <- mean((p5 - test$Moisture)^2)
p6 <- predict(m6, newdata = test, type = "response")
mseTest6 <- mean((p6 - test$Moisture)^2)
mseTest <- c(mseTest1, mseTest2, mseTest3, mseTest4, mseTest5, mseTest6)
#Plot booth MSE-arrays.
plot(mseTrain, type="b", col="blue", pch="o", lty=1, xlim=c(0, 7), ylim=c(30, 35))
points(mseTest, type ="b", col="red", pch="*")
#-------------------------------------------------------------------
library("MASS")
channelFat <- data[, 2:102]
model <- lm(Fat ~ ., data = channelFat)
#stepAIC with how many coefficients are chosen.
step <- stepAIC(model, direction="both")
step$anova
summary(step)
step$rank
#-------------------------------------------------------------------
library("glmnet")
#Ridge
covariates=scale(data[, 2:101])
response=scale(data[, 102])
ridge <- glmnet(as.matrix(covariates), response, alpha=0, family="gaussian")
#-------------------------------------------------------------------
#Lasso
lasso <- glmnet(as.matrix(covariates), response, alpha=1, family="gaussian")
#Plot lasso and ridge together.
par(mfrow=c(1,2))
plot(lasso, xvar="lambda", label=TRUE, xlim=c(-7, 0), ylim=c(-3, 5))
plot(ridge, xvar="lambda", label=TRUE, xlim=c(-3, 7), ylim=c(-0.18, 0.35))
#-------------------------------------------------------------------
#Cross-validation
cvLasso <- cv.glmnet(as.matrix(covariates), response, alpha=1, family="gaussian")
cvLasso$lambda.min
plot(cvLasso)
coef(cvLasso, s="lambda.min")
#-------------------------------------------------------------------
library("MASS")
channelFat <- data[, 2:102]
model <- lm(Fat ~ ., data = channelFat)
#stepAIC with how many coefficients are chosen.
step <- stepAIC(model, direction="both")
step$anova
summary(step)
step$rank
#-------------------------------------------------------------------
library("glmnet")
#Ridge
covariates=scale(data[, 2:101])
response=scale(data[, 102])
ridge <- glmnet(as.matrix(covariates), response, alpha=0, family="gaussian")
#-------------------------------------------------------------------
#Lasso
lasso <- glmnet(as.matrix(covariates), response, alpha=1, family="gaussian")
#Plot lasso and ridge together.
par(mfrow=c(1,2))
plot(lasso, xvar="lambda", label=TRUE, xlim=c(-7, 0), ylim=c(-3, 5))
plot(ridge, xvar="lambda", label=TRUE, xlim=c(-3, 7), ylim=c(-0.18, 0.35))
#-------------------------------------------------------------------
#Cross-validation
cvLasso <- cv.glmnet(as.matrix(covariates), response, alpha=1, family="gaussian")
cvLasso$lambda.min
plot(cvLasso)
coef(cvLasso, s="lambda.min")
#-------------------------------------------------------------------
#Cross-validation
lambda = seq(0,3, length = 1000)
cvLasso <- cv.glmnet(as.matrix(covariates), response, lambda=lambda, alpha=1, family="gaussian")
cvLasso$lambda.min
plot(cvLasso)
coef(cvLasso, s="lambda.min")
View(cvLasso)
cvLasso$glmnet.fit
#Lab 1
#Assignment 2
#Loading the data from machines.csv.
data <- read.csv2(file="machines.csv", header=TRUE)
#Function for calculating the loglikelihood.
calculateProbability = function(x, theta) {
n = dim(x)[1]
probability = n*log(theta) - theta*sum(x)
return(probability)
}
#Select x number of values between minData and maxData.
theta = seq(min(data), max(data), length.out = 1000)
#loglikelihood.
logLikelihood = calculateProbability(data, theta)
bestThetaLogLikelihood = theta[which.max(logLikelihood)]
#6 first observations.
firstSix = as.data.frame(data[1:6, ])
logLikelihoodSix = calculateProbability(firstSix, theta)
plot(theta, logLikelihood, type="l", ylim = c(-150, 0), xlab="Theta", ylab="Log Likelihood", main="Log Likelihood and theta", col="red")
lines(theta, logLikelihoodSix, col="blue")
#-------------------------------------------------------------------
#Prior + theta
bayesian <- logLikelihood + log(10) - 10*theta
lines(theta, bayesian, col="green")
bestThetaBayesian <- theta[which.max(bayesian)]
#-------------------------------------------------------------------
set.seed(12345)
newObservations <- rexp(50, rate = bestThetaLogLikelihood)
#Histograms.
par(mfrow=c(1,2))
hist(data$Length, col="red", breaks=15)
hist(newObservations, col="blue", breaks = 15)
par(mfrow=c(1,1))
#Lab 1
#Assignment 2
#Loading the data from machines.csv.
data <- read.csv2(file="machines.csv", header=TRUE)
#Function for calculating the loglikelihood.
calculateProbability = function(x, theta) {
n = dim(x)[1]
probability = n*log(theta) - theta*sum(x)
return(probability)
}
#Select x number of values between minData and maxData.
theta = seq(min(data), max(data), length.out = 1000)
#loglikelihood.
logLikelihood = calculateProbability(data, theta)
bestThetaLogLikelihood = theta[which.max(logLikelihood)]
#6 first observations.
firstSix = as.data.frame(data[1:6, ])
logLikelihoodSix = calculateProbability(firstSix, theta)
plot(theta, logLikelihood, type="l", ylim = c(-150, 0), xlab="Theta", ylab="Log Likelihood", main="Log Likelihood and theta", col="red")
lines(theta, logLikelihoodSix, col="blue")
#-------------------------------------------------------------------
#Prior + theta
bayesian <- logLikelihood + log(10) - 10*theta
lines(theta, bayesian, col="green")
bestThetaBayesian <- theta[which.max(bayesian)]
#-------------------------------------------------------------------
set.seed(12345)
newObservations <- rexp(50, rate = bestThetaLogLikelihood)
#Histograms.
par(mfrow=c(1,2))
hist(data$Length, breaks=15)
hist(newObservations, breaks = 15)
par(mfrow=c(1,1))
#Loading the data from tecator.csv.
data <- read.csv2(file="tecator.csv", header=TRUE)
#Checking if a linear model makes sense.
plot(data$Moisture ~ data$Protein) #Yes
#Dividing data into training and test sets.
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
train=data[id,]
test=data[-id,]
#Creating m1-m6 with different degrees. Maybe do a loop?
m1 <- lm(Moisture ~ poly(Protein, degree = 1, raw = TRUE), data = train)
train1 <- predict(m1, newdata = poly(train, degree = 1, raw = TRUE), type = "response")
m2 <- lm(Moisture ~ poly(Protein, degree = 2, raw = TRUE), data = train)
train2 <- predict(m1, newdata = poly(train, degree = 2, raw = TRUE), type = "response")
m3 <- lm(Moisture ~ poly(Protein, degree = 3, raw = TRUE), data = train)
train3 <- predict(m1, newdata = poly(train, degree = 3, raw = TRUE), type = "response")
m4 <- lm(Moisture ~ poly(Protein, degree = 4, raw = TRUE), data = train)
train4 <- predict(m1, newdata = poly(train, degree = 4, raw = TRUE), type = "response")
m5 <- lm(Moisture ~ poly(Protein, degree = 5, raw = TRUE), data = train)
train5 <- predict(m1, newdata = poly(train, degree = 5, raw = TRUE), type = "response")
m6 <- lm(Moisture ~ poly(Protein, degree = 6, raw = TRUE), data = train)
train6 <- predict(m1, newdata = poly(train, degree = 6, raw = TRUE), type = "response")
View(train)
train6 <- predict(m1, newdata = poly(train, degree = 6, raw = TRUE), type = "response")
train1 <- predict(m1, newdata = train, type = "response")
#Creating m1-m6 with different degrees. Maybe do a loop?
m1 <- lm(Moisture ~ poly(Protein, degree = 1, raw = TRUE), data = train)
train1 <- predict(m1, newdata = train, type = "response")
m2 <- lm(Moisture ~ poly(Protein, degree = 2, raw = TRUE), data = train)
train2 <- predict(m1, newdata = train, type = "response")
m3 <- lm(Moisture ~ poly(Protein, degree = 3, raw = TRUE), data = train)
train3 <- predict(m1, newdata = train, type = "response")
m4 <- lm(Moisture ~ poly(Protein, degree = 4, raw = TRUE), data = train)
train4 <- predict(m1, newdata = train, type = "response")
m5 <- lm(Moisture ~ poly(Protein, degree = 5, raw = TRUE), data = train)
train5 <- predict(m1, newdata = train, type = "response")
m6 <- lm(Moisture ~ poly(Protein, degree = 6, raw = TRUE), data = train)
train6 <- predict(m1, newdata = train, type = "response")
#Calculating MSE for the training data.
mseTrain1 <- mean((train1 - train$Moisture)^2)
mseTrain2 <- mean((train2 - train$Moisture)^2)
mseTrain3 <- mean((train3 - train$Moisture)^2)
mseTrain4 <- mean((train4 - train$Moisture)^2)
#Creating m1-m6 with different degrees. Maybe do a loop?
m1 <- lm(Moisture ~ poly(Protein, degree = 1, raw = TRUE), data = train)
train1 <- predict(m1, newdata = train, type = "response")
m2 <- lm(Moisture ~ poly(Protein, degree = 2, raw = TRUE), data = train)
train2 <- predict(m2, newdata = train, type = "response")
m3 <- lm(Moisture ~ poly(Protein, degree = 3, raw = TRUE), data = train)
train3 <- predict(m3, newdata = train, type = "response")
m4 <- lm(Moisture ~ poly(Protein, degree = 4, raw = TRUE), data = train)
train4 <- predict(m4, newdata = train, type = "response")
m5 <- lm(Moisture ~ poly(Protein, degree = 5, raw = TRUE), data = train)
train5 <- predict(m5, newdata = train, type = "response")
m6 <- lm(Moisture ~ poly(Protein, degree = 6, raw = TRUE), data = train)
train6 <- predict(m6, newdata = train, type = "response")
#Calculating MSE for the training data.
mseTrain1 <- mean((train1 - train$Moisture)^2)
mseTrain2 <- mean((train2 - train$Moisture)^2)
mseTrain3 <- mean((train3 - train$Moisture)^2)
mseTrain4 <- mean((train4 - train$Moisture)^2)
mseTrain5 <- mean((train5 - train$Moisture)^2)
mseTrain6 <- mean((train6 - train$Moisture)^2)
mseTrain <- c(mseTrain1, mseTrain2, mseTrain3, mseTrain4, mseTrain5, mseTrain6)
#Predicting with the test data and calculating the MSE.
test1 <- predict(m1, newdata = test, type = "response")
mseTest1 <- mean((test1 - test$Moisture)^2)
test2 <- predict(m2, newdata = test, type = "response")
test3 <- predict(m3, newdata = test, type = "response")
mseTest2 <- mean((test2 - test$Moisture)^2)
mseTest3 <- mean((test3 - test$Moisture)^2)
test4 <- predict(m4, newdata = test, type = "response")
mseTest4 <- mean((test4 - test$Moisture)^2)
test5 <- predict(m5, newdata = test, type = "response")
mseTest5 <- mean((test5 - test$Moisture)^2)
test6 <- predict(m6, newdata = test, type = "response")
mseTest6 <- mean((test6 - test$Moisture)^2)
mseTest <- c(mseTest1, mseTest2, mseTest3, mseTest4, mseTest5, mseTest6)
#Plot booth MSE-arrays.
plot(mseTrain, type="b", col="blue", pch="o", lty=1, xlim=c(0, 7), ylim=c(30, 35))
points(mseTest, type ="b", col="red", pch="*")
train1 <- predict(m1, newdata = poly(Protein, degree = 1, raw = TRUE), type = "response")
train1 <- predict(m1, newdata = poly(train, degree = 1, raw = TRUE), type = "response")
step$rank
source('~/R/Lab1/Lab1Assignment4.R')
step$rank
source('~/R/Lab1/Lab1Assignment4.R')
#-------------------------------------------------------------------
#Cross-validation
lambda = seq(0,3, length = 1000)
cvLasso <- cv.glmnet(as.matrix(covariates), response, lambda=lambda, alpha=1, family="gaussian")
cvLasso$lambda.min
plot(cvLasso)
coef(cvLasso, s="lambda.min")
cvLasso$lambda.min
#-------------------------------------------------------------------
#Cross-validation
cvLasso <- cv.glmnet(as.matrix(covariates), response, alpha=1, family="gaussian")
cvLasso$lambda.min
plot(cvLasso)
coef(cvLasso, s="lambda.min")
table(Actual_value = train$Spam, Predicted_value = trainProbability0.9)
View(cvLasso)
install.packages("readxl")
setwd("~/R/Lab3")
# Assignment 1. Kernel methods.
set.seed(1234567890)
library("geosphere")
stations <- read.csv("stations.csv")
temps <- read.csv("temps50k.csv")
st <- merge(stations,temps,by="station_number")
View(st)
